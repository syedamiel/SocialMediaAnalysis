{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM8kF6ZgZwlezunhgWZl95Y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/syedamiel/SocialMediaAnalysis/blob/main/Web_and_Social_Media_Analytics_MAS_TikTok(Part_2).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initial cleaning for TikTok comments"
      ],
      "metadata": {
        "id": "372y4nIT0kWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import json\n",
        "from datetime import datetime\n",
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "file_path = \"/content/dataset_tiktok-comments-scraper_2025-03-28_01-13-55-183.json\"\n",
        "\n",
        "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "    data = json.load(file)\n",
        "\n",
        "# Extract relevant data\n",
        "extracted_data = []\n",
        "comment_count = 0\n",
        "\n",
        "for comment in data:\n",
        "    comment_info = {\n",
        "        \"video_url\": comment.get(\"videoWebUrl\", \"\"),\n",
        "        \"timestamp\": comment.get(\"createTimeISO\", \"\"),\n",
        "        \"username\": comment.get(\"uniqueId\", \"\"),\n",
        "        \"comment_text\": comment.get(\"text\", \"\"),\n",
        "        \"likes\": comment.get(\"diggCount\", 0),\n",
        "        \"replies\": comment.get(\"replyCommentTotal\", 0),\n",
        "    }\n",
        "\n",
        "    extracted_data.append(comment_info)\n",
        "    comment_count += 1\n",
        "\n",
        "print(f\"Extracted {comment_count} comments.\")\n",
        "\n",
        "# Convert timestamps\n",
        "for comment in extracted_data:\n",
        "    if comment[\"timestamp\"]:\n",
        "        comment[\"timestamp\"] = datetime.strptime(\n",
        "            comment[\"timestamp\"], \"%Y-%m-%dT%H:%M:%S.%fZ\"\n",
        "        ).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "\n",
        "# Prepare data for CSV export\n",
        "csv_data = [\n",
        "    [c[\"video_url\"], c[\"timestamp\"], c[\"username\"], c[\"comment_text\"], c[\"likes\"], c[\"replies\"]]\n",
        "    for c in extracted_data\n",
        "]\n",
        "\n",
        "# Ensure all data is properly formatted (convert None values to empty strings)\n",
        "csv_data_clean = [[str(item) if item is not None else \"\" for item in row] for row in csv_data]\n",
        "\n",
        "# Create a DataFrame\n",
        "df = pd.DataFrame(csv_data_clean, columns=[\"Video URL\", \"Timestamp\", \"Username\", \"Comment Text\", \"Likes\", \"Replies\"])\n",
        "\n",
        "# Debugging - Print sample data\n",
        "print(df.head(10))\n",
        "print(df.dtypes)\n",
        "\n",
        "# Define the output file path\n",
        "excel_file_path = \"/content/cleaned_tiktok_comments.xlsx\"\n",
        "\n",
        "# Export to Excel\n",
        "df.to_excel(excel_file_path, index=False)\n",
        "\n",
        "print(f\"Filtered data saved to: {excel_file_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hcP1sEvouZ-s",
        "outputId": "60a89da3-a21c-4ce5-97ce-f1df995335a5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted 612 comments.\n",
            "                                           Video URL            Timestamp  \\\n",
            "0  https://www.tiktok.com/@malaysiaairlines/video...  2025-03-26 10:35:53   \n",
            "1  https://www.tiktok.com/@malaysiaairlines/video...  2025-03-26 14:14:19   \n",
            "2  https://www.tiktok.com/@malaysiaairlines/video...  2025-03-26 12:40:24   \n",
            "3  https://www.tiktok.com/@malaysiaairlines/video...  2025-03-27 21:25:32   \n",
            "4  https://www.tiktok.com/@malaysiaairlines/video...  2025-03-26 19:47:41   \n",
            "5  https://www.tiktok.com/@malaysiaairlines/video...  2025-03-26 16:41:45   \n",
            "6  https://www.tiktok.com/@malaysiaairlines/video...  2025-03-27 05:16:03   \n",
            "7  https://www.tiktok.com/@malaysiaairlines/video...  2025-03-26 13:02:49   \n",
            "8  https://www.tiktok.com/@malaysiaairlines/video...  2025-03-25 21:45:53   \n",
            "9  https://www.tiktok.com/@malaysiaairlines/video...  2025-03-24 13:06:04   \n",
            "\n",
            "            Username                                       Comment Text Likes  \\\n",
            "0        syafiq_.171                                 first comment üôãüèª‚úàÔ∏è     0   \n",
            "1             mie_lo                                              third     0   \n",
            "2            wag0468                   Hi can anyone help me for MH370?     0   \n",
            "3     fit_for_flight  Day 212 of asking for the business class ticke...     0   \n",
            "4     fit_for_flight  Day 211 of asking for the business class ticke...     0   \n",
            "5     bukanwalaunpas                     Menyesal undi PAS konoha hmm üôÇ     0   \n",
            "6  kostumpaskibra.id  Hello Malaysia airline i need help for my tick...     0   \n",
            "7   haziqalfadani230                                            HALO üòÜüçó     1   \n",
            "8     fit_for_flight  Day 210 of asking for the business class ticke...     1   \n",
            "9  batlikesaviation_  KUL (Kuala Lumpur)-CDG (Charless De Gaulle) fl...     1   \n",
            "\n",
            "  Replies  \n",
            "0       0  \n",
            "1       0  \n",
            "2       0  \n",
            "3       0  \n",
            "4       0  \n",
            "5       0  \n",
            "6       0  \n",
            "7       0  \n",
            "8       0  \n",
            "9       4  \n",
            "Video URL       object\n",
            "Timestamp       object\n",
            "Username        object\n",
            "Comment Text    object\n",
            "Likes           object\n",
            "Replies         object\n",
            "dtype: object\n",
            "Filtered data saved to: /content/cleaned_tiktok_comments.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The below one works as well for the Posts/Videos"
      ],
      "metadata": {
        "id": "XKMwnkVr3dw8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "input_file_path = \"/content/dataset_tiktok-profile-scraper_2025-03-27_08-56-41-895.json\"\n",
        "output_file_path = \"/content/cleaned_tiktok_posts.xlsx\"\n",
        "\n",
        "with open(input_file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "    data = json.load(file)\n",
        "\n",
        "# Define the required keys and order\n",
        "required_keys = [\"id\", \"text\", \"createTimeISO\", \"webVideoUrl\", \"diggCount\",\n",
        "                 \"shareCount\", \"playCount\", \"collectCount\", \"commentCount\", \"videoDuration\"]\n",
        "\n",
        "# Clean the dataset while maintaining order\n",
        "cleaned_data = []\n",
        "for entry in data:\n",
        "    cleaned_entry = {key: entry.get(key, None) for key in required_keys if key != \"videoDuration\"}\n",
        "\n",
        "    # Extract video duration from nested \"videoMeta\" dictionary\n",
        "    cleaned_entry[\"videoDuration\"] = entry.get(\"videoMeta\", {}).get(\"duration\", None)\n",
        "\n",
        "    cleaned_data.append(cleaned_entry)\n",
        "\n",
        "# Convert to DataFrame with the specified column order\n",
        "df = pd.DataFrame(cleaned_data, columns=required_keys)\n",
        "\n",
        "# Save the cleaned data to an Excel file\n",
        "df.to_excel(output_file_path, index=False)\n",
        "\n",
        "print(f\"Cleaned data saved to: {output_file_path}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XDACBnvnyM0f",
        "outputId": "b0656e6a-800e-4a3c-80e9-5bf31037dab0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaned data saved to: /content/cleaned_tiktok_posts.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langdetect"
      ],
      "metadata": {
        "id": "vb_6c7vdo2Hy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7e53838-8bbf-4dc9-c98e-d2ecf65b75ad"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langdetect\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[?25l     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/981.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m122.9/981.5 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[91m‚ï∏\u001b[0m \u001b[32m972.8/981.5 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from langdetect) (1.17.0)\n",
            "Building wheels for collected packages: langdetect\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993223 sha256=f389890c7e00d25710fcd854af6d9c13648fc4c5ad0c288d2c1210c0b5122c70\n",
            "  Stored in directory: /root/.cache/pip/wheels/0a/f2/b2/e5ca405801e05eb7c8ed5b3b4bcf1fcabcd6272c167640072e\n",
            "Successfully built langdetect\n",
            "Installing collected packages: langdetect\n",
            "Successfully installed langdetect-1.0.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Merge Posts file and Comments file to match comments to a posts using Video URL"
      ],
      "metadata": {
        "id": "zy9TxGImXqoG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from langdetect import detect, DetectorFactory\n",
        "from langdetect.lang_detect_exception import LangDetectException\n",
        "\n",
        "# Ensure consistent language detection results\n",
        "DetectorFactory.seed = 0\n",
        "\n",
        "# Load the TikTok posts dataset\n",
        "posts_df = pd.read_excel(\"/content/cleaned_tiktok_posts.xlsx\", engine=\"openpyxl\")\n",
        "\n",
        "# Load the TikTok comments dataset\n",
        "comments_df = pd.read_excel(\"/content/cleaned_tiktok_comments.xlsx\", engine=\"openpyxl\")\n",
        "\n",
        "# Display the first few rows to check the structure\n",
        "print(\"Posts DataFrame:\")\n",
        "print(posts_df.head())\n",
        "\n",
        "print(\"\\nComments DataFrame:\")\n",
        "print(comments_df.head())\n",
        "\n",
        "# Rename the 'videoWebUrl' column in posts_df to 'Video URL' for merging\n",
        "posts_df = posts_df.rename(columns={\"webVideoUrl\": \"Video URL\"})\n",
        "\n",
        "# Ensure both datasets have a 'URL' column for merging\n",
        "if \"Video URL\" not in posts_df.columns or \"Video URL\" not in comments_df.columns:\n",
        "    raise KeyError(\"Both datasets must contain a 'URL' column to merge.\")\n",
        "\n",
        "# Merge the datasets on the 'URL' column\n",
        "merged_df = comments_df.merge(posts_df, on=\"Video URL\", how=\"inner\")\n",
        "\n",
        "# Function to detect language (handling exceptions)\n",
        "def detect_language(text):\n",
        "    try:\n",
        "        return detect(text)\n",
        "    except LangDetectException:\n",
        "        return \"unknown\"\n",
        "\n",
        "# Apply language detection to the comments column\n",
        "merged_df[\"language\"] = merged_df[\"Comment Text\"].astype(str).apply(detect_language)\n",
        "\n",
        "# Keep only English comments\n",
        "english_comments_df = merged_df[merged_df[\"language\"] == \"en\"].drop(columns=[\"language\"])\n",
        "\n",
        "# Save the cleaned data to a new Excel file\n",
        "output_filename = \"cleaned-tiktok-data.xlsx\"\n",
        "english_comments_df.to_excel(output_filename, index=False, engine=\"openpyxl\")\n",
        "\n",
        "print(f\"\\nProcessing complete! Cleaned data saved as: {output_filename}\")\n"
      ],
      "metadata": {
        "id": "6FtjdbdtoGQ8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6e59c9f-0233-4fbe-8b98-22be14e75936"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Posts DataFrame:\n",
            "                    id                                               text  \\\n",
            "0  7486021286582406407  Explore Surabaya with Malaysia Airlines üåø\\n\\nD...   \n",
            "1  7486057349388487943  Discover Singapore with Malaysia Airlines ‚úàÔ∏è‚Äã\\...   \n",
            "2  7485333454524026129  Bonjour, Paris! Fly with Malaysia Airlines to ...   \n",
            "3  7484970389886520592  Bonjour, Paris! \\n\\nLast night, we took off fr...   \n",
            "4  7484291637737164053  We‚Äôre getting ready to take off to the City of...   \n",
            "\n",
            "              createTimeISO  \\\n",
            "0  2025-03-26T13:00:00.000Z   \n",
            "1  2025-03-26T10:05:54.000Z   \n",
            "2  2025-03-24T13:00:00.000Z   \n",
            "3  2025-03-23T11:48:25.000Z   \n",
            "4  2025-03-22T02:00:00.000Z   \n",
            "\n",
            "                                         webVideoUrl  diggCount  shareCount  \\\n",
            "0  https://www.tiktok.com/@malaysiaairlines/video...         54           1   \n",
            "1  https://www.tiktok.com/@malaysiaairlines/video...         52           1   \n",
            "2  https://www.tiktok.com/@malaysiaairlines/video...        223           3   \n",
            "3  https://www.tiktok.com/@malaysiaairlines/video...       1210         135   \n",
            "4  https://www.tiktok.com/@malaysiaairlines/video...       2284         180   \n",
            "\n",
            "   playCount  collectCount  commentCount  videoDuration  \n",
            "0        882             4             4             28  \n",
            "1        711             1             3             30  \n",
            "2       3014            22            11             31  \n",
            "3      19500            63            44             62  \n",
            "4      30600           200            91             42  \n",
            "\n",
            "Comments DataFrame:\n",
            "                                           Video URL            Timestamp  \\\n",
            "0  https://www.tiktok.com/@malaysiaairlines/video...  2025-03-26 10:35:53   \n",
            "1  https://www.tiktok.com/@malaysiaairlines/video...  2025-03-26 14:14:19   \n",
            "2  https://www.tiktok.com/@malaysiaairlines/video...  2025-03-26 12:40:24   \n",
            "3  https://www.tiktok.com/@malaysiaairlines/video...  2025-03-27 21:25:32   \n",
            "4  https://www.tiktok.com/@malaysiaairlines/video...  2025-03-26 19:47:41   \n",
            "\n",
            "         Username                                       Comment Text  Likes  \\\n",
            "0     syafiq_.171                                 first comment üôãüèª‚úàÔ∏è      0   \n",
            "1          mie_lo                                              third      0   \n",
            "2         wag0468                   Hi can anyone help me for MH370?      0   \n",
            "3  fit_for_flight  Day 212 of asking for the business class ticke...      0   \n",
            "4  fit_for_flight  Day 211 of asking for the business class ticke...      0   \n",
            "\n",
            "   Replies  \n",
            "0      0.0  \n",
            "1      0.0  \n",
            "2      0.0  \n",
            "3      0.0  \n",
            "4      0.0  \n",
            "\n",
            "Processing complete! Cleaned data saved as: cleaned-tiktok-data.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sentiment Analysis"
      ],
      "metadata": {
        "id": "LTV-CpSJXyxF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas openpyxl textblob"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mgimd9HMX3Aa",
        "outputId": "d3383db4-122c-4959-a1c1-1e1926a7bea3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.11/dist-packages (3.1.5)\n",
            "Requirement already satisfied: textblob in /usr/local/lib/python3.11/dist-packages (0.19.0)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl) (2.0.0)\n",
            "Requirement already satisfied: nltk>=3.9 in /usr/local/lib/python3.11/dist-packages (from textblob) (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk>=3.9->textblob) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk>=3.9->textblob) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk>=3.9->textblob) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk>=3.9->textblob) (4.67.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from textblob import TextBlob\n",
        "\n",
        "# Load the cleaned TikTok data\n",
        "input_filename = \"/content/cleaned-tiktok-data.xlsx\"\n",
        "df = pd.read_excel(input_filename, engine=\"openpyxl\")\n",
        "\n",
        "# Function to analyze sentiment\n",
        "def get_sentiment(text):\n",
        "    analysis = TextBlob(str(text))  # Ensure text is a string\n",
        "    polarity = analysis.sentiment.polarity  # Get sentiment polarity\n",
        "\n",
        "    # Classify sentiment based on polarity score\n",
        "    if polarity > 0:\n",
        "        return \"Positive\"\n",
        "    elif polarity < 0:\n",
        "        return \"Negative\"\n",
        "    else:\n",
        "        return \"Neutral\"\n",
        "\n",
        "# Apply sentiment analysis to the 'Comment Text' column\n",
        "df[\"Sentiment\"] = df[\"Comment Text\"].apply(get_sentiment)\n",
        "\n",
        "# Save the updated dataset with sentiment analysis\n",
        "output_filename = \"tiktok-data-with-sentiment.xlsx\"\n",
        "df.to_excel(output_filename, index=False, engine=\"openpyxl\")\n",
        "\n",
        "print(f\"\\nSentiment analysis complete! Data saved as: {output_filename}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SI5Q2dzZX1up",
        "outputId": "65bbbeda-7e33-434f-eca7-8b8c1ddabe2e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sentiment analysis complete! Data saved as: tiktok-data-with-sentiment.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sentiment Analysis using vaderSentiment (less accurate)"
      ],
      "metadata": {
        "id": "HMK8bCrwZyGR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas openpyxl vaderSentiment"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZJRO2I96ZYq8",
        "outputId": "7a9ed05e-5cdd-46d1-ac2d-1f7a1791a719"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.11/dist-packages (3.1.5)\n",
            "Collecting vaderSentiment\n",
            "  Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl.metadata (572 bytes)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl) (2.0.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from vaderSentiment) (2.32.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->vaderSentiment) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->vaderSentiment) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->vaderSentiment) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->vaderSentiment) (2025.1.31)\n",
            "Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m126.0/126.0 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: vaderSentiment\n",
            "Successfully installed vaderSentiment-3.3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "\n",
        "# Load the cleaned TikTok data\n",
        "input_filename = \"/content/cleaned-tiktok-data.xlsx\"\n",
        "df = pd.read_excel(input_filename, engine=\"openpyxl\")\n",
        "\n",
        "# Initialize VADER Sentiment Analyzer\n",
        "analyzer = SentimentIntensityAnalyzer()\n",
        "\n",
        "# Function to determine sentiment\n",
        "def get_vader_sentiment(text):\n",
        "    scores = analyzer.polarity_scores(str(text))  # Get sentiment scores\n",
        "    compound_score = scores[\"compound\"]  # Use compound score for classification\n",
        "\n",
        "    # Classify based on compound score thresholds\n",
        "    if compound_score >= 0.05:\n",
        "        return \"Positive\"\n",
        "    elif compound_score <= -0.05:\n",
        "        return \"Negative\"\n",
        "    else:\n",
        "        return \"Neutral\"\n",
        "\n",
        "# Apply sentiment analysis to the 'Comment Text' column\n",
        "df[\"Sentiment\"] = df[\"Comment Text\"].apply(get_vader_sentiment)\n",
        "\n",
        "# Save the updated dataset with sentiment analysis\n",
        "output_filename = \"tiktok-data-with-vader-sentiment.xlsx\"\n",
        "df.to_excel(output_filename, index=False, engine=\"openpyxl\")\n",
        "\n",
        "print(f\"\\nSentiment analysis complete! Data saved as: {output_filename}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HXEMYwYAZWBk",
        "outputId": "2fbc3954-8083-4244-ff5f-a40ed92a29e1"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sentiment analysis complete! Data saved as: tiktok-data-with-vader-sentiment.xlsx\n"
          ]
        }
      ]
    }
  ]
}