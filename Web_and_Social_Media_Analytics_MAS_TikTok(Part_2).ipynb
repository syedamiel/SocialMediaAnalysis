{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM8kF6ZgZwlezunhgWZl95Y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/syedamiel/SocialMediaAnalysis/blob/main/Web_and_Social_Media_Analytics_MAS_TikTok(Part_2).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initial cleaning for TikTok comments"
      ],
      "metadata": {
        "id": "372y4nIT0kWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import json\n",
        "from datetime import datetime\n",
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "file_path = \"/content/dataset_tiktok-comments-scraper_2025-03-28_01-13-55-183.json\"\n",
        "\n",
        "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "    data = json.load(file)\n",
        "\n",
        "# Extract relevant data\n",
        "extracted_data = []\n",
        "comment_count = 0\n",
        "\n",
        "for comment in data:\n",
        "    comment_info = {\n",
        "        \"video_url\": comment.get(\"videoWebUrl\", \"\"),\n",
        "        \"timestamp\": comment.get(\"createTimeISO\", \"\"),\n",
        "        \"username\": comment.get(\"uniqueId\", \"\"),\n",
        "        \"comment_text\": comment.get(\"text\", \"\"),\n",
        "        \"likes\": comment.get(\"diggCount\", 0),\n",
        "        \"replies\": comment.get(\"replyCommentTotal\", 0),\n",
        "    }\n",
        "\n",
        "    extracted_data.append(comment_info)\n",
        "    comment_count += 1\n",
        "\n",
        "print(f\"Extracted {comment_count} comments.\")\n",
        "\n",
        "# Convert timestamps\n",
        "for comment in extracted_data:\n",
        "    if comment[\"timestamp\"]:\n",
        "        comment[\"timestamp\"] = datetime.strptime(\n",
        "            comment[\"timestamp\"], \"%Y-%m-%dT%H:%M:%S.%fZ\"\n",
        "        ).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "\n",
        "# Prepare data for CSV export\n",
        "csv_data = [\n",
        "    [c[\"video_url\"], c[\"timestamp\"], c[\"username\"], c[\"comment_text\"], c[\"likes\"], c[\"replies\"]]\n",
        "    for c in extracted_data\n",
        "]\n",
        "\n",
        "# Ensure all data is properly formatted (convert None values to empty strings)\n",
        "csv_data_clean = [[str(item) if item is not None else \"\" for item in row] for row in csv_data]\n",
        "\n",
        "# Create a DataFrame\n",
        "df = pd.DataFrame(csv_data_clean, columns=[\"Video URL\", \"Timestamp\", \"Username\", \"Comment Text\", \"Likes\", \"Replies\"])\n",
        "\n",
        "# Debugging - Print sample data\n",
        "print(df.head(10))\n",
        "print(df.dtypes)\n",
        "\n",
        "# Define the output file path\n",
        "excel_file_path = \"/content/cleaned_tiktok_comments.xlsx\"\n",
        "\n",
        "# Export to Excel\n",
        "df.to_excel(excel_file_path, index=False)\n",
        "\n",
        "print(f\"Filtered data saved to: {excel_file_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hcP1sEvouZ-s",
        "outputId": "60a89da3-a21c-4ce5-97ce-f1df995335a5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted 612 comments.\n",
            "                                           Video URL            Timestamp  \\\n",
            "0  https://www.tiktok.com/@malaysiaairlines/video...  2025-03-26 10:35:53   \n",
            "1  https://www.tiktok.com/@malaysiaairlines/video...  2025-03-26 14:14:19   \n",
            "2  https://www.tiktok.com/@malaysiaairlines/video...  2025-03-26 12:40:24   \n",
            "3  https://www.tiktok.com/@malaysiaairlines/video...  2025-03-27 21:25:32   \n",
            "4  https://www.tiktok.com/@malaysiaairlines/video...  2025-03-26 19:47:41   \n",
            "5  https://www.tiktok.com/@malaysiaairlines/video...  2025-03-26 16:41:45   \n",
            "6  https://www.tiktok.com/@malaysiaairlines/video...  2025-03-27 05:16:03   \n",
            "7  https://www.tiktok.com/@malaysiaairlines/video...  2025-03-26 13:02:49   \n",
            "8  https://www.tiktok.com/@malaysiaairlines/video...  2025-03-25 21:45:53   \n",
            "9  https://www.tiktok.com/@malaysiaairlines/video...  2025-03-24 13:06:04   \n",
            "\n",
            "            Username                                       Comment Text Likes  \\\n",
            "0        syafiq_.171                                 first comment ðŸ™‹ðŸ»âœˆï¸     0   \n",
            "1             mie_lo                                              third     0   \n",
            "2            wag0468                   Hi can anyone help me for MH370?     0   \n",
            "3     fit_for_flight  Day 212 of asking for the business class ticke...     0   \n",
            "4     fit_for_flight  Day 211 of asking for the business class ticke...     0   \n",
            "5     bukanwalaunpas                     Menyesal undi PAS konoha hmm ðŸ™‚     0   \n",
            "6  kostumpaskibra.id  Hello Malaysia airline i need help for my tick...     0   \n",
            "7   haziqalfadani230                                            HALO ðŸ˜†ðŸ—     1   \n",
            "8     fit_for_flight  Day 210 of asking for the business class ticke...     1   \n",
            "9  batlikesaviation_  KUL (Kuala Lumpur)-CDG (Charless De Gaulle) fl...     1   \n",
            "\n",
            "  Replies  \n",
            "0       0  \n",
            "1       0  \n",
            "2       0  \n",
            "3       0  \n",
            "4       0  \n",
            "5       0  \n",
            "6       0  \n",
            "7       0  \n",
            "8       0  \n",
            "9       4  \n",
            "Video URL       object\n",
            "Timestamp       object\n",
            "Username        object\n",
            "Comment Text    object\n",
            "Likes           object\n",
            "Replies         object\n",
            "dtype: object\n",
            "Filtered data saved to: /content/cleaned_tiktok_comments.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The below one works as well for the Posts/Videos"
      ],
      "metadata": {
        "id": "XKMwnkVr3dw8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "input_file_path = \"/content/dataset_tiktok-profile-scraper_2025-03-27_08-56-41-895.json\"\n",
        "output_file_path = \"/content/cleaned_tiktok_posts.xlsx\"\n",
        "\n",
        "with open(input_file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "    data = json.load(file)\n",
        "\n",
        "# Define the required keys and order\n",
        "required_keys = [\"id\", \"text\", \"createTimeISO\", \"webVideoUrl\", \"diggCount\",\n",
        "                 \"shareCount\", \"playCount\", \"collectCount\", \"commentCount\", \"videoDuration\"]\n",
        "\n",
        "# Clean the dataset while maintaining order\n",
        "cleaned_data = []\n",
        "for entry in data:\n",
        "    cleaned_entry = {key: entry.get(key, None) for key in required_keys if key != \"videoDuration\"}\n",
        "\n",
        "    # Extract video duration from nested \"videoMeta\" dictionary\n",
        "    cleaned_entry[\"videoDuration\"] = entry.get(\"videoMeta\", {}).get(\"duration\", None)\n",
        "\n",
        "    cleaned_data.append(cleaned_entry)\n",
        "\n",
        "# Convert to DataFrame with the specified column order\n",
        "df = pd.DataFrame(cleaned_data, columns=required_keys)\n",
        "\n",
        "# Save the cleaned data to an Excel file\n",
        "df.to_excel(output_file_path, index=False)\n",
        "\n",
        "print(f\"Cleaned data saved to: {output_file_path}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XDACBnvnyM0f",
        "outputId": "b0656e6a-800e-4a3c-80e9-5bf31037dab0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaned data saved to: /content/cleaned_tiktok_posts.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langdetect"
      ],
      "metadata": {
        "id": "vb_6c7vdo2Hy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7e53838-8bbf-4dc9-c98e-d2ecf65b75ad"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langdetect\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[?25l     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/981.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91mâ”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m122.9/981.5 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m \u001b[32m972.8/981.5 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from langdetect) (1.17.0)\n",
            "Building wheels for collected packages: langdetect\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993223 sha256=f389890c7e00d25710fcd854af6d9c13648fc4c5ad0c288d2c1210c0b5122c70\n",
            "  Stored in directory: /root/.cache/pip/wheels/0a/f2/b2/e5ca405801e05eb7c8ed5b3b4bcf1fcabcd6272c167640072e\n",
            "Successfully built langdetect\n",
            "Installing collected packages: langdetect\n",
            "Successfully installed langdetect-1.0.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Merge Posts file and Comments file to match comments to a posts using Video URL"
      ],
      "metadata": {
        "id": "zy9TxGImXqoG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from langdetect import detect, DetectorFactory\n",
        "from langdetect.lang_detect_exception import LangDetectException\n",
        "\n",
        "# Ensure consistent language detection results\n",
        "DetectorFactory.seed = 0\n",
        "\n",
        "# Load the TikTok posts dataset\n",
        "posts_df = pd.read_excel(\"/content/cleaned_tiktok_posts.xlsx\", engine=\"openpyxl\")\n",
        "\n",
        "# Load the TikTok comments dataset\n",
        "comments_df = pd.read_excel(\"/content/cleaned_tiktok_comments.xlsx\", engine=\"openpyxl\")\n",
        "\n",
        "# Display the first few rows to check the structure\n",
        "print(\"Posts DataFrame:\")\n",
        "print(posts_df.head())\n",
        "\n",
        "print(\"\\nComments DataFrame:\")\n",
        "print(comments_df.head())\n",
        "\n",
        "# Rename the 'videoWebUrl' column in posts_df to 'Video URL' for merging\n",
        "posts_df = posts_df.rename(columns={\"webVideoUrl\": \"Video URL\"})\n",
        "\n",
        "# Ensure both datasets have a 'URL' column for merging\n",
        "if \"Video URL\" not in posts_df.columns or \"Video URL\" not in comments_df.columns:\n",
        "    raise KeyError(\"Both datasets must contain a 'URL' column to merge.\")\n",
        "\n",
        "# Merge the datasets on the 'URL' column\n",
        "merged_df = comments_df.merge(posts_df, on=\"Video URL\", how=\"inner\")\n",
        "\n",
        "# Function to detect language (handling exceptions)\n",
        "def detect_language(text):\n",
        "    try:\n",
        "        return detect(text)\n",
        "    except LangDetectException:\n",
        "        return \"unknown\"\n",
        "\n",
        "# Apply language detection to the comments column\n",
        "merged_df[\"language\"] = merged_df[\"Comment Text\"].astype(str).apply(detect_language)\n",
        "\n",
        "# Keep only English comments\n",
        "english_comments_df = merged_df[merged_df[\"language\"] == \"en\"].drop(columns=[\"language\"])\n",
        "\n",
        "# Save the cleaned data to a new Excel file\n",
        "output_filename = \"cleaned-tiktok-data.xlsx\"\n",
        "english_comments_df.to_excel(output_filename, index=False, engine=\"openpyxl\")\n",
        "\n",
        "print(f\"\\nProcessing complete! Cleaned data saved as: {output_filename}\")\n"
      ],
      "metadata": {
        "id": "6FtjdbdtoGQ8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6e59c9f-0233-4fbe-8b98-22be14e75936"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Posts DataFrame:\n",
            "                    id                                               text  \\\n",
            "0  7486021286582406407  Explore Surabaya with Malaysia Airlines ðŸŒ¿\\n\\nD...   \n",
            "1  7486057349388487943  Discover Singapore with Malaysia Airlines âœˆï¸â€‹\\...   \n",
            "2  7485333454524026129  Bonjour, Paris! Fly with Malaysia Airlines to ...   \n",
            "3  7484970389886520592  Bonjour, Paris! \\n\\nLast night, we took off fr...   \n",
            "4  7484291637737164053  Weâ€™re getting ready to take off to the City of...   \n",
            "\n",
            "              createTimeISO  \\\n",
            "0  2025-03-26T13:00:00.000Z   \n",
            "1  2025-03-26T10:05:54.000Z   \n",
            "2  2025-03-24T13:00:00.000Z   \n",
            "3  2025-03-23T11:48:25.000Z   \n",
            "4  2025-03-22T02:00:00.000Z   \n",
            "\n",
            "                                         webVideoUrl  diggCount  shareCount  \\\n",
            "0  https://www.tiktok.com/@malaysiaairlines/video...         54           1   \n",
            "1  https://www.tiktok.com/@malaysiaairlines/video...         52           1   \n",
            "2  https://www.tiktok.com/@malaysiaairlines/video...        223           3   \n",
            "3  https://www.tiktok.com/@malaysiaairlines/video...       1210         135   \n",
            "4  https://www.tiktok.com/@malaysiaairlines/video...       2284         180   \n",
            "\n",
            "   playCount  collectCount  commentCount  videoDuration  \n",
            "0        882             4             4             28  \n",
            "1        711             1             3             30  \n",
            "2       3014            22            11             31  \n",
            "3      19500            63            44             62  \n",
            "4      30600           200            91             42  \n",
            "\n",
            "Comments DataFrame:\n",
            "                                           Video URL            Timestamp  \\\n",
            "0  https://www.tiktok.com/@malaysiaairlines/video...  2025-03-26 10:35:53   \n",
            "1  https://www.tiktok.com/@malaysiaairlines/video...  2025-03-26 14:14:19   \n",
            "2  https://www.tiktok.com/@malaysiaairlines/video...  2025-03-26 12:40:24   \n",
            "3  https://www.tiktok.com/@malaysiaairlines/video...  2025-03-27 21:25:32   \n",
            "4  https://www.tiktok.com/@malaysiaairlines/video...  2025-03-26 19:47:41   \n",
            "\n",
            "         Username                                       Comment Text  Likes  \\\n",
            "0     syafiq_.171                                 first comment ðŸ™‹ðŸ»âœˆï¸      0   \n",
            "1          mie_lo                                              third      0   \n",
            "2         wag0468                   Hi can anyone help me for MH370?      0   \n",
            "3  fit_for_flight  Day 212 of asking for the business class ticke...      0   \n",
            "4  fit_for_flight  Day 211 of asking for the business class ticke...      0   \n",
            "\n",
            "   Replies  \n",
            "0      0.0  \n",
            "1      0.0  \n",
            "2      0.0  \n",
            "3      0.0  \n",
            "4      0.0  \n",
            "\n",
            "Processing complete! Cleaned data saved as: cleaned-tiktok-data.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sentiment Analysis"
      ],
      "metadata": {
        "id": "LTV-CpSJXyxF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas openpyxl textblob"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mgimd9HMX3Aa",
        "outputId": "d3383db4-122c-4959-a1c1-1e1926a7bea3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.11/dist-packages (3.1.5)\n",
            "Requirement already satisfied: textblob in /usr/local/lib/python3.11/dist-packages (0.19.0)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl) (2.0.0)\n",
            "Requirement already satisfied: nltk>=3.9 in /usr/local/lib/python3.11/dist-packages (from textblob) (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk>=3.9->textblob) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk>=3.9->textblob) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk>=3.9->textblob) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk>=3.9->textblob) (4.67.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from textblob import TextBlob\n",
        "\n",
        "# Load the cleaned TikTok data\n",
        "input_filename = \"/content/cleaned-tiktok-data.xlsx\"\n",
        "df = pd.read_excel(input_filename, engine=\"openpyxl\")\n",
        "\n",
        "# Function to analyze sentiment\n",
        "def get_sentiment(text):\n",
        "    analysis = TextBlob(str(text))  # Ensure text is a string\n",
        "    polarity = analysis.sentiment.polarity  # Get sentiment polarity\n",
        "\n",
        "    # Classify sentiment based on polarity score\n",
        "    if polarity > 0:\n",
        "        return \"Positive\"\n",
        "    elif polarity < 0:\n",
        "        return \"Negative\"\n",
        "    else:\n",
        "        return \"Neutral\"\n",
        "\n",
        "# Apply sentiment analysis to the 'Comment Text' column\n",
        "df[\"Sentiment\"] = df[\"Comment Text\"].apply(get_sentiment)\n",
        "\n",
        "# Save the updated dataset with sentiment analysis\n",
        "output_filename = \"tiktok-data-with-sentiment.xlsx\"\n",
        "df.to_excel(output_filename, index=False, engine=\"openpyxl\")\n",
        "\n",
        "print(f\"\\nSentiment analysis complete! Data saved as: {output_filename}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SI5Q2dzZX1up",
        "outputId": "65bbbeda-7e33-434f-eca7-8b8c1ddabe2e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sentiment analysis complete! Data saved as: tiktok-data-with-sentiment.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sentiment Analysis using vaderSentiment (less accurate)"
      ],
      "metadata": {
        "id": "HMK8bCrwZyGR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas openpyxl vaderSentiment"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZJRO2I96ZYq8",
        "outputId": "7a9ed05e-5cdd-46d1-ac2d-1f7a1791a719"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.11/dist-packages (3.1.5)\n",
            "Collecting vaderSentiment\n",
            "  Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl.metadata (572 bytes)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl) (2.0.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from vaderSentiment) (2.32.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->vaderSentiment) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->vaderSentiment) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->vaderSentiment) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->vaderSentiment) (2025.1.31)\n",
            "Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m126.0/126.0 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: vaderSentiment\n",
            "Successfully installed vaderSentiment-3.3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "\n",
        "# Load the cleaned TikTok data\n",
        "input_filename = \"/content/cleaned-tiktok-data.xlsx\"\n",
        "df = pd.read_excel(input_filename, engine=\"openpyxl\")\n",
        "\n",
        "# Initialize VADER Sentiment Analyzer\n",
        "analyzer = SentimentIntensityAnalyzer()\n",
        "\n",
        "# Function to determine sentiment\n",
        "def get_vader_sentiment(text):\n",
        "    scores = analyzer.polarity_scores(str(text))  # Get sentiment scores\n",
        "    compound_score = scores[\"compound\"]  # Use compound score for classification\n",
        "\n",
        "    # Classify based on compound score thresholds\n",
        "    if compound_score >= 0.05:\n",
        "        return \"Positive\"\n",
        "    elif compound_score <= -0.05:\n",
        "        return \"Negative\"\n",
        "    else:\n",
        "        return \"Neutral\"\n",
        "\n",
        "# Apply sentiment analysis to the 'Comment Text' column\n",
        "df[\"Sentiment\"] = df[\"Comment Text\"].apply(get_vader_sentiment)\n",
        "\n",
        "# Save the updated dataset with sentiment analysis\n",
        "output_filename = \"tiktok-data-with-vader-sentiment.xlsx\"\n",
        "df.to_excel(output_filename, index=False, engine=\"openpyxl\")\n",
        "\n",
        "print(f\"\\nSentiment analysis complete! Data saved as: {output_filename}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HXEMYwYAZWBk",
        "outputId": "2fbc3954-8083-4244-ff5f-a40ed92a29e1"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sentiment analysis complete! Data saved as: tiktok-data-with-vader-sentiment.xlsx\n"
          ]
        }
      ]
    }
  ]
}